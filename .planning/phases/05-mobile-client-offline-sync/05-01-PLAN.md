---
phase: 05-mobile-client-offline-sync
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/omnii_mcp/supabase/migrations/YYYYMMDD_powersync_tables.sql
  - apps/omnii_mcp/src/routes/powersync.ts
  - apps/omnii_mcp/src/routes/index.ts
autonomous: true

must_haves:
  truths:
    - "Supabase has sync_entities table for PowerSync to sync"
    - "Supabase has sync_events table for calendar/timeline data"
    - "PowerSync can read data via sync endpoint"
  artifacts:
    - path: "apps/omnii_mcp/supabase/migrations/YYYYMMDD_powersync_tables.sql"
      provides: "PowerSync-compatible sync tables"
      contains: "CREATE TABLE sync_entities"
    - path: "apps/omnii_mcp/src/routes/powersync.ts"
      provides: "PowerSync sync endpoint for mobile"
      exports: ["powerSyncRoutes"]
  key_links:
    - from: "apps/omnii_mcp/src/routes/powersync.ts"
      to: "Supabase sync tables"
      via: "Supabase client queries"
      pattern: "supabase\\.from\\('sync_"
---

<objective>
Create Supabase tables optimized for PowerSync synchronization and expose sync endpoint for mobile app.

Purpose: PowerSync needs PostgreSQL tables with specific patterns (id, updated_at columns) to track changes and sync to mobile SQLite. The MCP backend provides the data; these tables cache it for efficient mobile sync.

Output: Migration file creating sync tables + HTTP endpoint PowerSync can poll.
</objective>

<execution_context>
@/Users/santino/.claude/get-shit-done/workflows/execute-plan.md
@/Users/santino/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-mobile-client-offline-sync/05-RESEARCH.md
@apps/omnii_mcp/src/services/supabase.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PowerSync-compatible Supabase tables</name>
  <files>apps/omnii_mcp/supabase/migrations/20260125_powersync_tables.sql</files>
  <action>
Create migration file with tables optimized for PowerSync:

1. `sync_entities` table - stores graph entities for mobile sync:
   - id (UUID, primary key)
   - user_id (UUID, references auth.users, required for RLS)
   - entity_type (TEXT: 'task', 'email', 'contact', 'concept')
   - name (TEXT)
   - properties (JSONB - flexible key-value storage)
   - source_id (TEXT - original ID from Google/Neo4j for deduplication)
   - created_at (TIMESTAMPTZ, default now())
   - updated_at (TIMESTAMPTZ, default now(), required for PowerSync change tracking)

2. `sync_events` table - stores calendar events:
   - id (UUID, primary key)
   - user_id (UUID, references auth.users)
   - summary (TEXT)
   - description (TEXT)
   - start_time (TIMESTAMPTZ)
   - end_time (TIMESTAMPTZ)
   - location (TEXT)
   - google_event_id (TEXT, unique for deduplication)
   - attendees (JSONB)
   - created_at (TIMESTAMPTZ)
   - updated_at (TIMESTAMPTZ)

3. `sync_relationships` table - stores entity relationships:
   - id (UUID, primary key)
   - user_id (UUID)
   - from_entity_id (UUID, references sync_entities)
   - to_entity_id (UUID, references sync_entities)
   - relationship_type (TEXT: 'ATTENDED', 'SENT_BY', 'MENTIONS', etc.)
   - properties (JSONB)
   - created_at (TIMESTAMPTZ)
   - updated_at (TIMESTAMPTZ)

Add RLS policies:
- Users can only read/write their own data (user_id = auth.uid())
- Enable RLS on all tables

Add indexes:
- Composite index on (user_id, updated_at) for PowerSync change queries
- Index on entity_type for filtering
- Index on source_id for deduplication lookups

Add trigger for auto-updating updated_at on row changes.
  </action>
  <verify>Run `bunx supabase db push` or check migration file syntax with `bunx supabase db lint`</verify>
  <done>Migration file exists, tables have id, user_id, updated_at columns, RLS enabled</done>
</task>

<task type="auto">
  <name>Task 2: Create PowerSync HTTP endpoint</name>
  <files>apps/omnii_mcp/src/routes/powersync.ts, apps/omnii_mcp/src/routes/index.ts</files>
  <action>
Create Elysia route module for PowerSync sync operations:

1. Create `apps/omnii_mcp/src/routes/powersync.ts`:

```typescript
import { Elysia, t } from 'elysia';
import { authMiddleware } from '../middleware/auth';
import { supabaseAdmin } from '../services/supabase';

export const powerSyncRoutes = new Elysia({ prefix: '/api/powersync' })
  .use(authMiddleware)

  // GET /api/powersync/sync - Main sync endpoint
  // Returns changes since last sync timestamp
  .get('/sync', async ({ query, auth }) => {
    const { since, tables, limit = '1000' } = query;
    const userId = auth.tenantId;

    const sinceDate = since ? new Date(since) : new Date(0);
    const tableList = tables ? tables.split(',') : ['sync_entities', 'sync_events', 'sync_relationships'];
    const limitNum = Math.min(parseInt(limit), 5000);

    const changes: Record<string, any[]> = {};

    for (const table of tableList) {
      const { data, error } = await supabaseAdmin
        .from(table)
        .select('*')
        .eq('user_id', userId)
        .gt('updated_at', sinceDate.toISOString())
        .order('updated_at', { ascending: true })
        .limit(limitNum);

      if (!error && data) {
        changes[table] = data;
      }
    }

    return {
      changes,
      timestamp: new Date().toISOString(),
      hasMore: Object.values(changes).some(arr => arr.length >= limitNum)
    };
  }, {
    query: t.Object({
      since: t.Optional(t.String()),
      tables: t.Optional(t.String()),
      limit: t.Optional(t.String())
    })
  })

  // POST /api/powersync/upload - Receive changes from mobile
  .post('/upload', async ({ body, auth }) => {
    const { changes } = body;
    const userId = auth.tenantId;

    const results: Record<string, { success: number; errors: string[] }> = {};

    for (const [table, operations] of Object.entries(changes)) {
      results[table] = { success: 0, errors: [] };

      for (const op of operations as any[]) {
        try {
          switch (op.type) {
            case 'PUT':
              await supabaseAdmin.from(table).upsert({
                ...op.data,
                user_id: userId,
                updated_at: new Date().toISOString()
              });
              break;
            case 'DELETE':
              await supabaseAdmin.from(table).delete().eq('id', op.id).eq('user_id', userId);
              break;
          }
          results[table].success++;
        } catch (err: any) {
          results[table].errors.push(err.message);
        }
      }
    }

    return { results, timestamp: new Date().toISOString() };
  }, {
    body: t.Object({
      changes: t.Record(t.String(), t.Array(t.Any()))
    })
  })

  // GET /api/powersync/health - Health check for mobile
  .get('/health', async ({ auth }) => ({
    status: 'ok',
    userId: auth.tenantId,
    timestamp: new Date().toISOString()
  }));
```

2. Register routes in `apps/omnii_mcp/src/routes/index.ts`:
   - Import `powerSyncRoutes` from './powersync'
   - Add `.use(powerSyncRoutes)` to the routes chain
  </action>
  <verify>
Run server with `bun run dev` in apps/omnii_mcp, then:
- `curl -X GET http://localhost:3001/api/powersync/health -H "Authorization: Bearer $TOKEN"` returns 200
- Check `/swagger` shows the new powersync endpoints
  </verify>
  <done>PowerSync routes mounted at /api/powersync/*, health endpoint returns status</done>
</task>

<task type="auto">
  <name>Task 3: Populate sync tables from existing graph data</name>
  <files>apps/omnii_mcp/src/routes/powersync.ts</files>
  <action>
Add a sync trigger endpoint that populates Supabase sync tables from Neo4j graph data:

Add to `powerSyncRoutes`:

```typescript
// POST /api/powersync/populate - Sync Neo4j data to Supabase tables (manual trigger)
.post('/populate', async ({ auth }) => {
  const userId = auth.tenantId;

  // Import graph service
  const { neo4jService } = await import('../services/neo4j');

  let entitiesSynced = 0;
  let eventsSynced = 0;
  let relationshipsSynced = 0;

  try {
    // 1. Sync Entity nodes (Contact, Concept, Task emails)
    const entities = await neo4jService.listNodes(userId, 'Entity', 500);
    for (const entity of entities) {
      await supabaseAdmin.from('sync_entities').upsert({
        id: entity.id,
        user_id: userId,
        entity_type: entity.properties?.entity_type || 'entity',
        name: entity.properties?.name || entity.properties?.title || 'Unnamed',
        properties: entity.properties || {},
        source_id: entity.properties?.google_task_id || entity.properties?.gmail_message_id || entity.id,
        updated_at: new Date().toISOString()
      }, { onConflict: 'id' });
      entitiesSynced++;
    }

    // 2. Sync Contact nodes
    const contacts = await neo4jService.listNodes(userId, 'Contact', 500);
    for (const contact of contacts) {
      await supabaseAdmin.from('sync_entities').upsert({
        id: contact.id,
        user_id: userId,
        entity_type: 'contact',
        name: contact.properties?.name || contact.properties?.email || 'Unknown',
        properties: contact.properties || {},
        source_id: contact.properties?.google_contact_id || contact.id,
        updated_at: new Date().toISOString()
      }, { onConflict: 'id' });
      entitiesSynced++;
    }

    // 3. Sync Event nodes
    const events = await neo4jService.listNodes(userId, 'Event', 500);
    for (const event of events) {
      await supabaseAdmin.from('sync_events').upsert({
        id: event.id,
        user_id: userId,
        summary: event.properties?.summary || event.properties?.title || 'Untitled',
        description: event.properties?.description,
        start_time: event.properties?.start_time,
        end_time: event.properties?.end_time,
        location: event.properties?.location,
        google_event_id: event.properties?.google_event_id,
        attendees: event.properties?.attendees || [],
        updated_at: new Date().toISOString()
      }, { onConflict: 'id' });
      eventsSynced++;
    }

    return {
      success: true,
      synced: {
        entities: entitiesSynced,
        events: eventsSynced,
        relationships: relationshipsSynced
      },
      timestamp: new Date().toISOString()
    };

  } catch (error: any) {
    return {
      success: false,
      error: error.message,
      synced: { entities: entitiesSynced, events: eventsSynced, relationships: relationshipsSynced }
    };
  }
}, {
  detail: {
    summary: 'Populate sync tables from Neo4j graph',
    description: 'Copies graph data to Supabase tables for mobile PowerSync'
  }
});
```

This provides a way to initially populate sync tables and can be triggered after ingestion.
  </action>
  <verify>
After running `curl -X POST http://localhost:3001/api/powersync/populate -H "Authorization: Bearer $TOKEN"`, query sync tables:
`SELECT COUNT(*) FROM sync_entities; SELECT COUNT(*) FROM sync_events;` shows non-zero counts.
  </verify>
  <done>POST /api/powersync/populate syncs Neo4j data to Supabase sync tables</done>
</task>

</tasks>

<verification>
1. Migration file exists at expected path with correct table structure
2. All three tables have: id, user_id, updated_at columns
3. RLS policies enabled on all tables
4. PowerSync routes respond at /api/powersync/*
5. Swagger shows powersync endpoints
6. /populate endpoint can sync data from Neo4j to Supabase
</verification>

<success_criteria>
- Supabase has sync_entities, sync_events, sync_relationships tables
- Tables have PowerSync-required columns (id UUID, updated_at TIMESTAMPTZ)
- RLS restricts access to user's own data
- HTTP endpoints at /api/powersync/sync, /upload, /health, /populate work
- Mobile can fetch changes since timestamp via /sync endpoint
</success_criteria>

<output>
After completion, create `.planning/phases/05-mobile-client-offline-sync/05-01-SUMMARY.md`
</output>
