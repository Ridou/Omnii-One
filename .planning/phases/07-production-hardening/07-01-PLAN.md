---
phase: 07-production-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/omnii_mcp/package.json
  - apps/omnii_mcp/src/services/observability/sentry.ts
  - apps/omnii_mcp/src/services/observability/telemetry.ts
  - apps/omnii_mcp/src/services/observability/metrics.ts
  - apps/omnii_mcp/src/services/observability/index.ts
  - apps/omnii_mcp/src/index.ts
autonomous: true

must_haves:
  truths:
    - "Backend errors are captured and sent to Sentry"
    - "API latency is tracked per route"
    - "Graph query performance is measured"
    - "Sync duration is logged as structured metrics"
  artifacts:
    - path: "apps/omnii_mcp/src/services/observability/sentry.ts"
      provides: "Sentry initialization and error capture"
      exports: ["initSentry", "captureError"]
    - path: "apps/omnii_mcp/src/services/observability/metrics.ts"
      provides: "Performance metrics logging"
      exports: ["logMetric", "timedOperation"]
    - path: "apps/omnii_mcp/src/services/observability/telemetry.ts"
      provides: "OpenTelemetry configuration"
      exports: ["createTelemetryPlugin"]
  key_links:
    - from: "apps/omnii_mcp/src/index.ts"
      to: "services/observability"
      via: "initSentry() call at startup"
      pattern: "initSentry\\(\\)"
---

<objective>
Set up backend error tracking with Sentry and performance monitoring with OpenTelemetry to capture production issues and track API latency, graph query performance, and sync duration.

Purpose: Production issues need to be captured and reported, and performance needs to be monitored to meet success criteria 3 and 4.
Output: Observability services (Sentry, OpenTelemetry, metrics) integrated into backend startup.
</objective>

<execution_context>
@/Users/santino/.claude/get-shit-done/workflows/execute-plan.md
@/Users/santino/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-production-hardening/07-RESEARCH.md

Research provides:
- @sentry/bun ^8.x for backend error tracking
- @elysiajs/opentelemetry ^1.x for distributed tracing
- Pino-based metrics logging (already in use from Phase 6)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install observability dependencies</name>
  <files>apps/omnii_mcp/package.json</files>
  <action>
Add production observability dependencies to omnii_mcp:

```bash
cd apps/omnii_mcp && bun add @sentry/bun @elysiajs/opentelemetry @opentelemetry/sdk-node @opentelemetry/exporter-trace-otlp-proto
```

These provide:
- @sentry/bun: Official Sentry SDK for Bun runtime
- @elysiajs/opentelemetry: Official Elysia plugin for tracing
- @opentelemetry/sdk-node: Core OTel SDK
- @opentelemetry/exporter-trace-otlp-proto: OTLP trace exporter

After installation, verify packages appear in package.json dependencies.
  </action>
  <verify>Run `grep -E "sentry|opentelemetry" apps/omnii_mcp/package.json` shows all 4 packages</verify>
  <done>Dependencies installed and listed in package.json</done>
</task>

<task type="auto">
  <name>Task 2: Create observability services</name>
  <files>
    apps/omnii_mcp/src/services/observability/sentry.ts
    apps/omnii_mcp/src/services/observability/telemetry.ts
    apps/omnii_mcp/src/services/observability/metrics.ts
    apps/omnii_mcp/src/services/observability/index.ts
  </files>
  <action>
Create the observability service directory and files:

**sentry.ts** - Sentry initialization for backend:
```typescript
import * as Sentry from '@sentry/bun';

export function initSentry(): void {
  if (!process.env.SENTRY_DSN) {
    console.warn('[Sentry] No DSN configured, skipping initialization');
    return;
  }

  Sentry.init({
    dsn: process.env.SENTRY_DSN,
    environment: process.env.NODE_ENV || 'development',
    release: process.env.APP_VERSION || '1.0.0',
    tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.1 : 1.0,
    ignoreErrors: ['AbortError', 'NetworkError', 'TimeoutError'],
    beforeSend(event) {
      // Scrub PII from breadcrumbs
      if (event.breadcrumbs) {
        event.breadcrumbs = event.breadcrumbs.map(bc => {
          if (bc.data?.password) bc.data.password = '[REDACTED]';
          if (bc.data?.token) bc.data.token = '[REDACTED]';
          if (bc.data?.authorization) bc.data.authorization = '[REDACTED]';
          return bc;
        });
      }
      return event;
    },
  });

  console.log('[Sentry] Initialized for environment:', process.env.NODE_ENV || 'development');
}

export function captureError(error: Error, context?: Record<string, unknown>): void {
  Sentry.withScope(scope => {
    if (context?.userId) scope.setUser({ id: context.userId as string });
    if (context?.tags) {
      Object.entries(context.tags as Record<string, string>).forEach(([k, v]) => scope.setTag(k, v));
    }
    if (context?.extra) {
      Object.entries(context.extra as Record<string, unknown>).forEach(([k, v]) => scope.setExtra(k, v));
    }
    Sentry.captureException(error);
  });
}

export { Sentry };
```

**telemetry.ts** - OpenTelemetry plugin:
```typescript
import { opentelemetry } from '@elysiajs/opentelemetry';
import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-node';
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-proto';

export function createTelemetryPlugin() {
  // Skip in development if no collector configured
  const otlpEndpoint = process.env.OTEL_EXPORTER_OTLP_ENDPOINT;

  if (!otlpEndpoint && process.env.NODE_ENV !== 'production') {
    console.warn('[OpenTelemetry] No OTLP endpoint configured, using noop exporter');
    return opentelemetry({
      serviceName: 'omnii-mcp',
    });
  }

  return opentelemetry({
    serviceName: 'omnii-mcp',
    spanProcessors: otlpEndpoint
      ? [
          new BatchSpanProcessor(
            new OTLPTraceExporter({
              url: otlpEndpoint,
            })
          ),
        ]
      : undefined,
  });
}
```

**metrics.ts** - Performance metrics using existing Pino:
```typescript
import pino from 'pino';

export const metricsLogger = pino({
  name: 'omnii-metrics',
  level: 'info',
  base: {
    service: 'omnii-mcp',
    environment: process.env.NODE_ENV || 'development',
  },
  timestamp: pino.stdTimeFunctions.isoTime,
});

export interface ApiLatencyMetric {
  metric: 'api_latency';
  route: string;
  method: string;
  duration: number;
  status: number;
}

export interface GraphQueryMetric {
  metric: 'graph_query_duration';
  queryType: string;
  duration: number;
  resultCount?: number;
}

export interface SyncMetric {
  metric: 'sync_duration';
  source: 'calendar' | 'tasks' | 'gmail' | 'contacts';
  userId: string;
  duration: number;
  itemsSynced: number;
}

export type PerformanceMetric = ApiLatencyMetric | GraphQueryMetric | SyncMetric;

export function logMetric(metric: PerformanceMetric): void {
  metricsLogger.info(metric);
}

export async function timedOperation<T>(
  metricType: string,
  operation: () => Promise<T>
): Promise<{ result: T; duration: number }> {
  const start = performance.now();
  const result = await operation();
  const duration = performance.now() - start;

  metricsLogger.info({
    metric: 'operation_duration',
    operation: metricType,
    duration,
  });

  return { result, duration };
}
```

**index.ts** - Barrel export:
```typescript
export { initSentry, captureError, Sentry } from './sentry';
export { createTelemetryPlugin } from './telemetry';
export {
  metricsLogger,
  logMetric,
  timedOperation,
  type ApiLatencyMetric,
  type GraphQueryMetric,
  type SyncMetric,
  type PerformanceMetric,
} from './metrics';
```
  </action>
  <verify>Run `bun run check` from apps/omnii_mcp - no TypeScript errors</verify>
  <done>Observability services created with Sentry, OpenTelemetry, and metrics logging</done>
</task>

<task type="auto">
  <name>Task 3: Wire observability into application startup</name>
  <files>apps/omnii_mcp/src/index.ts</files>
  <action>
Update the main application entry point to initialize Sentry BEFORE Elysia, and add the OpenTelemetry plugin:

1. Import observability services at the top:
```typescript
import { initSentry, createTelemetryPlugin, logMetric } from './services/observability';
```

2. Call initSentry() BEFORE creating Elysia app:
```typescript
// Initialize Sentry before anything else
initSentry();
```

3. Add telemetry plugin to Elysia app (after other plugins):
```typescript
.use(createTelemetryPlugin())
```

4. Add timing middleware for API latency tracking using onRequest/onAfterResponse:
```typescript
.onRequest(({ store }) => {
  (store as any).requestStart = performance.now();
})
.onAfterResponse(({ request, store, set }) => {
  const duration = performance.now() - ((store as any).requestStart || 0);
  const url = new URL(request.url);

  logMetric({
    metric: 'api_latency',
    route: url.pathname,
    method: request.method,
    duration,
    status: typeof set.status === 'number' ? set.status : 200,
  });
})
```

Ensure the initialization order is:
1. initSentry() - first, before app
2. new Elysia() - create app
3. .use(createTelemetryPlugin()) - add telemetry
4. ... other plugins and routes
5. .onRequest/.onAfterResponse - add timing

Do NOT modify any existing route logic, only add observability wiring.
  </action>
  <verify>Run `bun run dev` from apps/omnii_mcp - app starts without errors, logs show Sentry and OpenTelemetry initialization</verify>
  <done>Backend starts with Sentry initialized and API latency tracking enabled</done>
</task>

</tasks>

<verification>
Run these checks after completing all tasks:

1. TypeScript compiles: `cd apps/omnii_mcp && bun run check`
2. App starts: `cd apps/omnii_mcp && bun run dev` - look for Sentry/OTel init logs
3. Metrics logged: Make a request to `/health`, check stdout for `api_latency` metric
4. Sentry captureError works: Import and call `captureError(new Error('test'))` in a test route

Note: Full Sentry verification requires SENTRY_DSN env var set with a real Sentry project.
</verification>

<success_criteria>
- Sentry SDK installed and initializes on startup (logs "[Sentry] Initialized")
- OpenTelemetry plugin configured (logs warning if no endpoint, doesn't crash)
- API latency tracked for all requests (metrics logger outputs api_latency events)
- timedOperation helper available for wrapping graph queries
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/07-production-hardening/07-01-SUMMARY.md`
</output>
