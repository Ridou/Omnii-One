---
phase: 08-file-ingestion-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - apps/omnii_mcp/src/ingestion/sources/files/validators/file-validator.ts
  - apps/omnii_mcp/src/ingestion/sources/files/parsers/pdf-parser.ts
  - apps/omnii_mcp/src/ingestion/sources/files/parsers/docx-parser.ts
  - apps/omnii_mcp/src/ingestion/sources/files/parsers/text-parser.ts
  - apps/omnii_mcp/src/ingestion/sources/files/parsers/index.ts
autonomous: true

must_haves:
  truths:
    - "Uploaded files are validated using magic number detection, not file extension"
    - "PDF files can be parsed to extract text content"
    - "Word documents (.docx) can be parsed to extract text content"
    - "Text and markdown files can be parsed"
  artifacts:
    - path: "apps/omnii_mcp/src/ingestion/sources/files/validators/file-validator.ts"
      provides: "MIME detection and security validation"
      exports: ["validateFile", "ValidationResult"]
    - path: "apps/omnii_mcp/src/ingestion/sources/files/parsers/pdf-parser.ts"
      provides: "PDF text extraction using unpdf"
      exports: ["parsePDF"]
    - path: "apps/omnii_mcp/src/ingestion/sources/files/parsers/docx-parser.ts"
      provides: "Word document text extraction using mammoth"
      exports: ["parseDOCX"]
    - path: "apps/omnii_mcp/src/ingestion/sources/files/parsers/text-parser.ts"
      provides: "Text/markdown file parsing"
      exports: ["parseText", "parseMarkdown"]
    - path: "apps/omnii_mcp/src/ingestion/sources/files/parsers/index.ts"
      provides: "Parser factory that routes to correct parser"
      exports: ["parseFile"]
  key_links:
    - from: "apps/omnii_mcp/src/ingestion/sources/files/parsers/index.ts"
      to: "apps/omnii_mcp/src/ingestion/sources/files/types.ts"
      via: "imports ParseResult, SupportedFileType"
      pattern: "import.*from.*types"
---

<objective>
Implement file validation (MIME detection) and parsers for PDF, Word, text, and markdown files.

Purpose: Enable secure file uploads with content-based validation, and extract text from uploaded documents.
Output: File validator using magic numbers, parsers for each supported file type.
</objective>

<execution_context>
@/Users/santino/.claude/get-shit-done/workflows/execute-plan.md
@/Users/santino/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-file-ingestion-pipeline/08-RESEARCH.md
@.planning/phases/08-file-ingestion-pipeline/08-01-SUMMARY.md

@apps/omnii_mcp/src/ingestion/sources/files/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create file validator with MIME detection</name>
  <files>apps/omnii_mcp/src/ingestion/sources/files/validators/file-validator.ts</files>
  <action>
Create the validators directory and file-validator.ts:

```
mkdir -p apps/omnii_mcp/src/ingestion/sources/files/validators
```

Implement file validation using file-type for magic number detection:

```typescript
/**
 * File Validator
 *
 * Security-critical validation using magic number detection.
 * NEVER trust file extensions - they can be spoofed.
 */

import { fileTypeFromBuffer } from 'file-type';
import { SUPPORTED_MIME_TYPES, CODE_EXTENSIONS, type SupportedFileType } from '../types';

/** Maximum file size: 50MB */
export const MAX_FILE_SIZE = 50 * 1024 * 1024;

/** Validation result */
export interface ValidationResult {
  valid: boolean;
  fileType?: SupportedFileType;
  mimeType?: string;
  error?: string;
}

/**
 * Validate uploaded file using magic number detection.
 *
 * Security: Uses binary signature analysis, not file extension.
 * This prevents file type spoofing attacks (e.g., malware.pdf.exe).
 *
 * @param buffer - File content as ArrayBuffer
 * @param originalName - Original filename (used only for code file detection)
 * @param fileSize - File size in bytes
 * @returns ValidationResult with detected type or error
 */
export async function validateFile(
  buffer: ArrayBuffer,
  originalName: string,
  fileSize: number
): Promise<ValidationResult> {
  // Check file size
  if (fileSize > MAX_FILE_SIZE) {
    return {
      valid: false,
      error: `File too large: ${(fileSize / 1024 / 1024).toFixed(1)}MB exceeds ${MAX_FILE_SIZE / 1024 / 1024}MB limit`,
    };
  }

  if (fileSize === 0) {
    return {
      valid: false,
      error: 'File is empty',
    };
  }

  // Detect MIME type from magic numbers
  const detected = await fileTypeFromBuffer(new Uint8Array(buffer));

  // Handle binary files (PDF, DOCX)
  if (detected) {
    const fileType = SUPPORTED_MIME_TYPES[detected.mime];
    if (fileType) {
      return {
        valid: true,
        fileType,
        mimeType: detected.mime,
      };
    }

    // Detected a binary file type we don't support
    return {
      valid: false,
      error: `Unsupported file type: ${detected.mime}. Supported: PDF, DOCX, TXT, MD, code files`,
    };
  }

  // No binary signature detected - could be text file
  // Validate it's actually text content (not binary garbage)
  const textValidation = validateTextContent(buffer);
  if (!textValidation.isText) {
    return {
      valid: false,
      error: 'File appears to be binary but type could not be detected. Supported: PDF, DOCX, TXT, MD, code files',
    };
  }

  // Determine if it's markdown, code, or plain text based on extension
  const ext = getExtension(originalName).toLowerCase();

  if (ext === '.md' || ext === '.markdown') {
    return {
      valid: true,
      fileType: 'md',
      mimeType: 'text/markdown',
    };
  }

  if (CODE_EXTENSIONS.includes(ext)) {
    return {
      valid: true,
      fileType: 'code',
      mimeType: 'text/plain',
    };
  }

  // Default to plain text
  return {
    valid: true,
    fileType: 'txt',
    mimeType: 'text/plain',
  };
}

/**
 * Check if buffer contains valid text content (not binary)
 */
function validateTextContent(buffer: ArrayBuffer): { isText: boolean } {
  const bytes = new Uint8Array(buffer);
  const sampleSize = Math.min(8192, bytes.length); // Check first 8KB

  let nullCount = 0;
  let controlCount = 0;

  for (let i = 0; i < sampleSize; i++) {
    const byte = bytes[i];

    // Count null bytes (common in binary files)
    if (byte === 0) {
      nullCount++;
    }

    // Count control characters (excluding common ones like tab, newline)
    if (byte < 32 && byte !== 9 && byte !== 10 && byte !== 13) {
      controlCount++;
    }
  }

  // If more than 1% null bytes or 5% control chars, likely binary
  const nullRatio = nullCount / sampleSize;
  const controlRatio = controlCount / sampleSize;

  return {
    isText: nullRatio < 0.01 && controlRatio < 0.05,
  };
}

/**
 * Get file extension from filename
 */
function getExtension(filename: string): string {
  const lastDot = filename.lastIndexOf('.');
  if (lastDot === -1 || lastDot === filename.length - 1) {
    return '';
  }
  return filename.slice(lastDot);
}

/**
 * Calculate SHA-256 hash for deduplication
 */
export async function calculateFileHash(buffer: ArrayBuffer): Promise<string> {
  const hasher = new Bun.CryptoHasher('sha256');
  hasher.update(buffer);
  return hasher.digest('hex');
}
```
  </action>
  <verify>
TypeScript compiles:
```
cd apps/omnii_mcp && bun build src/ingestion/sources/files/validators/file-validator.ts --outdir /tmp --target node
```
  </verify>
  <done>
file-validator.ts validates files using magic numbers, exports validateFile and calculateFileHash.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create PDF and Word parsers</name>
  <files>
apps/omnii_mcp/src/ingestion/sources/files/parsers/pdf-parser.ts
apps/omnii_mcp/src/ingestion/sources/files/parsers/docx-parser.ts
  </files>
  <action>
Create the parsers directory:
```
mkdir -p apps/omnii_mcp/src/ingestion/sources/files/parsers
```

Create pdf-parser.ts:

```typescript
/**
 * PDF Parser
 *
 * Extracts text from PDF documents using unpdf (PDF.js-based).
 * Includes confidence scoring for extraction quality.
 */

import { extractText, getDocumentProxy } from 'unpdf';
import type { ParseResult } from '../types';

/**
 * Parse PDF file and extract text content.
 *
 * @param buffer - PDF file content as ArrayBuffer
 * @returns ParseResult with extracted text and confidence score
 */
export async function parsePDF(buffer: ArrayBuffer): Promise<ParseResult> {
  try {
    const pdf = await getDocumentProxy(new Uint8Array(buffer));
    const { text, totalPages } = await extractText(pdf, { mergePages: true });

    // Calculate confidence based on extraction quality heuristics
    const confidence = calculatePDFConfidence(text, totalPages);

    return {
      text: text.trim(),
      metadata: {
        totalPages,
        format: 'pdf',
      },
      confidence,
    };
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    throw new Error(`PDF parsing failed: ${message}`);
  }
}

/**
 * Calculate confidence score for PDF extraction.
 *
 * Heuristics:
 * - Very low char/page ratio suggests scanned/image PDF (OCR not supported)
 * - Replacement characters suggest encoding issues
 * - Sparse content may indicate partial extraction
 */
function calculatePDFConfidence(text: string, totalPages: number): number {
  if (totalPages === 0) {
    return 0;
  }

  const avgCharsPerPage = text.length / totalPages;

  // Red flags that reduce confidence
  let confidence = 0.95;

  // Very low character count - likely scanned/image PDF
  if (avgCharsPerPage < 50) {
    confidence = 0.3; // Likely needs OCR (not supported)
  } else if (avgCharsPerPage < 200) {
    confidence = 0.7; // Sparse content, may be incomplete
  }

  // Replacement character (U+FFFD) indicates encoding issues
  const replacementCount = (text.match(/\ufffd/g) || []).length;
  if (replacementCount > 0) {
    const replacementRatio = replacementCount / text.length;
    confidence *= (1 - Math.min(0.5, replacementRatio * 10));
  }

  // Excessive whitespace ratio suggests layout extraction issues
  const whitespaceRatio = (text.match(/\s/g) || []).length / text.length;
  if (whitespaceRatio > 0.5) {
    confidence *= 0.9;
  }

  return Math.max(0.1, Math.min(1, confidence));
}
```

Create docx-parser.ts:

```typescript
/**
 * Word Document Parser
 *
 * Extracts text from .docx files using mammoth.
 * Includes confidence scoring based on extraction warnings.
 */

import mammoth from 'mammoth';
import type { ParseResult } from '../types';

/**
 * Parse Word document and extract text content.
 *
 * @param buffer - DOCX file content as ArrayBuffer
 * @returns ParseResult with extracted text and confidence score
 */
export async function parseDOCX(buffer: ArrayBuffer): Promise<ParseResult> {
  try {
    const result = await mammoth.extractRawText({
      buffer: Buffer.from(buffer),
    });

    // Mammoth reports warnings for elements it couldn't handle
    const warnings = result.messages.map((m) => m.message);
    const hasWarnings = warnings.length > 0;

    // Base confidence on warning count
    let confidence = 0.95;
    if (hasWarnings) {
      // Reduce confidence based on warning severity
      const warningPenalty = Math.min(0.25, warnings.length * 0.05);
      confidence -= warningPenalty;
    }

    return {
      text: result.value.trim(),
      metadata: {
        warnings,
        format: 'docx',
      },
      confidence,
    };
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    throw new Error(`DOCX parsing failed: ${message}`);
  }
}
```
  </action>
  <verify>
TypeScript compiles:
```
cd apps/omnii_mcp && bun build src/ingestion/sources/files/parsers/pdf-parser.ts --outdir /tmp --target node
cd apps/omnii_mcp && bun build src/ingestion/sources/files/parsers/docx-parser.ts --outdir /tmp --target node
```
  </verify>
  <done>
pdf-parser.ts and docx-parser.ts created with confidence scoring, both compile successfully.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create text/markdown parsers and parser index</name>
  <files>
apps/omnii_mcp/src/ingestion/sources/files/parsers/text-parser.ts
apps/omnii_mcp/src/ingestion/sources/files/parsers/index.ts
  </files>
  <action>
Create text-parser.ts:

```typescript
/**
 * Text and Markdown Parser
 *
 * Handles plain text, markdown, and code files.
 * These have simpler parsing - mainly UTF-8 decoding.
 */

import MarkdownIt from 'markdown-it';
import type { ParseResult } from '../types';

const md = new MarkdownIt();

/**
 * Parse plain text file.
 *
 * @param buffer - Text file content as ArrayBuffer
 * @returns ParseResult with text content
 */
export async function parseText(buffer: ArrayBuffer): Promise<ParseResult> {
  const decoder = new TextDecoder('utf-8', { fatal: false });
  const text = decoder.decode(buffer);

  // Check for encoding issues
  const replacementCount = (text.match(/\ufffd/g) || []).length;
  const confidence = replacementCount > 0
    ? Math.max(0.5, 1 - replacementCount / text.length * 10)
    : 0.98;

  return {
    text: text.trim(),
    metadata: {
      format: 'txt',
    },
    confidence,
  };
}

/**
 * Parse markdown file.
 *
 * Renders markdown to extract plain text for indexing.
 * Preserves structure for better chunking later.
 *
 * @param buffer - Markdown file content as ArrayBuffer
 * @returns ParseResult with text content
 */
export async function parseMarkdown(buffer: ArrayBuffer): Promise<ParseResult> {
  const decoder = new TextDecoder('utf-8', { fatal: false });
  const rawText = decoder.decode(buffer);

  // For indexing, we want the raw markdown (keeps headers, lists visible)
  // rather than rendered HTML stripped of markup
  // This preserves semantic structure for chunking
  const text = rawText.trim();

  // Check for encoding issues
  const replacementCount = (text.match(/\ufffd/g) || []).length;
  const confidence = replacementCount > 0
    ? Math.max(0.5, 1 - replacementCount / text.length * 10)
    : 0.98;

  return {
    text,
    metadata: {
      format: 'md',
    },
    confidence,
  };
}

/**
 * Parse code file.
 *
 * Similar to text parsing but with code-specific handling.
 * Future: Could use tree-sitter for AST-aware parsing.
 *
 * @param buffer - Code file content as ArrayBuffer
 * @returns ParseResult with code content
 */
export async function parseCode(buffer: ArrayBuffer): Promise<ParseResult> {
  const decoder = new TextDecoder('utf-8', { fatal: false });
  const text = decoder.decode(buffer);

  // Check for encoding issues
  const replacementCount = (text.match(/\ufffd/g) || []).length;
  const confidence = replacementCount > 0
    ? Math.max(0.5, 1 - replacementCount / text.length * 10)
    : 0.98;

  return {
    text: text.trim(),
    metadata: {
      format: 'code',
    },
    confidence,
  };
}
```

Create index.ts (parser factory):

```typescript
/**
 * Parser Factory
 *
 * Routes files to the appropriate parser based on detected type.
 */

import { parsePDF } from './pdf-parser';
import { parseDOCX } from './docx-parser';
import { parseText, parseMarkdown, parseCode } from './text-parser';
import type { ParseResult, SupportedFileType } from '../types';

/**
 * Parse a file using the appropriate parser for its type.
 *
 * @param buffer - File content as ArrayBuffer
 * @param fileType - Detected file type from validation
 * @returns ParseResult with extracted text and confidence
 */
export async function parseFile(
  buffer: ArrayBuffer,
  fileType: SupportedFileType
): Promise<ParseResult> {
  switch (fileType) {
    case 'pdf':
      return parsePDF(buffer);
    case 'docx':
      return parseDOCX(buffer);
    case 'txt':
      return parseText(buffer);
    case 'md':
      return parseMarkdown(buffer);
    case 'code':
      return parseCode(buffer);
    default:
      throw new Error(`Unsupported file type: ${fileType}`);
  }
}

// Re-export individual parsers for direct use
export { parsePDF } from './pdf-parser';
export { parseDOCX } from './docx-parser';
export { parseText, parseMarkdown, parseCode } from './text-parser';
```
  </action>
  <verify>
TypeScript compiles:
```
cd apps/omnii_mcp && bun build src/ingestion/sources/files/parsers/index.ts --outdir /tmp --target node
```
  </verify>
  <done>
text-parser.ts with parseText, parseMarkdown, parseCode created.
index.ts exports parseFile factory and individual parsers.
All files compile successfully.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:
1. All parser files compile without TypeScript errors
2. File validator uses magic number detection (not extension)
3. PDF parser returns confidence score based on extraction quality
4. DOCX parser returns confidence score based on warnings
5. Text/markdown parsers handle UTF-8 encoding
6. Parser factory routes to correct parser by file type
</verification>

<success_criteria>
- validateFile() uses file-type library for magic number MIME detection
- parsePDF() extracts text using unpdf with confidence scoring
- parseDOCX() extracts text using mammoth with warning-based confidence
- parseText(), parseMarkdown(), parseCode() handle text files
- parseFile() factory correctly routes to appropriate parser
- All files compile and export correctly
</success_criteria>

<output>
After completion, create `.planning/phases/08-file-ingestion-pipeline/08-02-SUMMARY.md`
</output>
